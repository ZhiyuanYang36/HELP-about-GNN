{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c91ce37-48c6-488d-9a8f-272531ee4cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5c1de5c-18d0-4e1f-93ed-4ce4586b3f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Node Features (x): tensor([[0.3745, 0.9507, 0.7320, 0.5987, 0.1560, 0.1560, 0.0581, 0.8662, 0.6011,\n",
      "         0.7081],\n",
      "        [0.1851, 0.5419, 0.8729, 0.7322, 0.8066, 0.6588, 0.6923, 0.8492, 0.2497,\n",
      "         0.4894],\n",
      "        [0.2617, 0.2470, 0.9063, 0.2495, 0.2719, 0.7594, 0.4497, 0.7767, 0.0654,\n",
      "         0.4876],\n",
      "        [0.6727, 0.7967, 0.2505, 0.6249, 0.5717, 0.8328, 0.9061, 0.0122, 0.6740,\n",
      "         0.0518]])\n",
      "Sample Edge Index: tensor([[20, 63, 36, 26, 54, 28, 19, 24, 69, 62, 35,  1, 21, 95, 15, 17, 68, 53,\n",
      "         99, 29, 44, 18, 86, 33, 12, 42, 61, 92, 99, 21, 51, 51, 35, 72, 18, 37,\n",
      "         69, 78, 56, 19,  8, 31,  3, 49, 81,  4, 19, 86, 74, 36, 21, 57, 67, 92,\n",
      "         43, 33, 76, 41,  8, 94,  6, 67, 18, 93, 30, 34, 56, 84, 60, 30, 82, 94,\n",
      "         52, 31, 65, 58,  9,  1, 65, 59, 87, 16, 95, 15, 15, 45, 38, 30, 87,  0,\n",
      "         10, 84,  3, 70, 25, 49, 11, 94, 80, 96, 74, 91, 95, 64, 46, 91, 52, 70,\n",
      "          1, 23,  3, 18, 25, 74, 39, 49, 42, 74, 66, 11, 66, 26, 53, 65, 48, 15,\n",
      "          1, 59, 53, 29, 83, 37, 27, 24, 95,  9, 59, 41, 39, 96, 76, 41, 46, 36,\n",
      "         79, 21, 56, 83, 26, 40, 79, 33, 31, 89, 88, 65, 11, 39, 72, 75, 89, 72,\n",
      "          9, 95, 97, 47, 19, 38, 59, 65, 64, 50, 35, 23, 26,  1, 30, 56, 77, 65,\n",
      "         28, 14, 11, 27, 83, 23, 20,  9, 77, 17, 87, 13, 33, 57, 75, 21, 69, 35,\n",
      "         44, 35],\n",
      "        [21, 77, 79, 60, 99, 55, 88, 95, 32, 44, 35, 19, 17, 37, 66, 22, 95, 15,\n",
      "         58, 68, 67, 20, 77, 94, 77, 69, 11, 15, 80, 86, 13, 60, 70, 45, 31, 14,\n",
      "         43, 16, 40, 53, 43, 97,  4, 26, 86, 77, 78, 42, 96, 30, 98, 16, 91, 82,\n",
      "         53, 61, 86, 31, 39, 12, 83, 34,  4, 72, 28, 69, 24, 94, 21, 65, 44, 68,\n",
      "         90, 88, 71,  0, 83, 43, 86, 95, 74, 38, 53, 87, 74, 28, 53, 89, 15, 98,\n",
      "         19, 45, 66, 64, 57, 52,  0, 80, 65, 28, 83, 69,  7, 28, 50, 32,  2, 59,\n",
      "         34, 68, 90, 75, 83, 19, 72, 38,  3, 18, 90, 44, 42, 12, 12, 59, 56, 85,\n",
      "         91, 51, 52, 85, 42, 82, 71, 71, 41, 89, 25, 22, 42, 76, 27,  8, 19, 55,\n",
      "         82, 38, 50, 11, 78, 94, 54, 77, 10, 25, 41, 26, 10, 37, 97, 42, 18, 63,\n",
      "          5, 45, 41, 91, 64, 98, 71, 58, 51, 46,  6, 10, 60, 67, 24, 11, 25, 11,\n",
      "         42, 50, 36, 45, 52, 87, 79, 12, 88, 53, 56,  3, 74, 95, 48,  6, 10, 91,\n",
      "         53, 86]])\n",
      "Sample External Features: tensor([[7.9001e-01, 3.1798e-01, 5.7973e-01, 3.4562e-01, 8.1577e-01, 4.6673e-01,\n",
      "         7.6723e-02, 1.6605e-01, 6.1105e-02, 4.9930e-01],\n",
      "        [1.0634e-01, 1.1414e-01, 9.4105e-01, 8.7266e-01, 4.5209e-01, 9.8581e-01,\n",
      "         1.8653e-04, 6.1398e-01, 6.1643e-01, 4.5744e-01]])\n",
      "Sample Target (y): tensor(0.1875)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\34184\\anaconda3\\Lib\\site-packages\\torch_geometric\\deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 设置随机种子以确保可重复性\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 定义常量\n",
    "num_nodes = 100  # 节点数量\n",
    "timesteps = 10   # 时间步数\n",
    "feature_dim = 4  # 节点特征维度（采纳率、产量、天气、土壤肥力）\n",
    "ext_feature_dim = 2  # 外部特征维度（市场和政策）\n",
    "\n",
    "# 1. 生成节点特征\n",
    "adoption_rate = np.random.rand(num_nodes, 1, timesteps)   # 采纳率\n",
    "yield_data = np.random.rand(num_nodes, 1, timesteps)      # 产量\n",
    "weather_data = np.random.rand(num_nodes, 1, timesteps)     # 天气\n",
    "soil_fertility = np.random.rand(num_nodes, 1, timesteps)   # 土壤肥力\n",
    "\n",
    "# 合并特征，形成形状为 [num_nodes, feature_dim, timesteps]\n",
    "x = np.concatenate((adoption_rate, yield_data, weather_data, soil_fertility), axis=1)  # shape: [num_nodes, feature_dim, timesteps]\n",
    "\n",
    "# 2. 生成边特征（地理位置和社交网络）\n",
    "# 示例：随机生成边（地理位置和社交网络关系）\n",
    "num_edges = 200  # 定义边的数量\n",
    "edge_index = np.random.randint(0, num_nodes, (2, num_edges))  # 形状：[2, num_edges]\n",
    "\n",
    "# 3. 生成外部特征（市场、政策）\n",
    "market_data = np.random.rand(num_nodes, ext_feature_dim, timesteps)  # 形状：[num_nodes, ext_feature_dim, timesteps]\n",
    "\n",
    "# 4. 生成目标变量（这里是一个示例）\n",
    "y = np.random.rand(num_nodes)  # 目标值（例如：未来的产量）\n",
    "\n",
    "# 5. 创建 Data 对象\n",
    "x_tensor = torch.tensor(x, dtype=torch.float32)  # 转换为 Tensor\n",
    "edge_index_tensor = torch.tensor(edge_index, dtype=torch.long)  # 转换为 Tensor\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)  # 转换为 Tensor\n",
    "market_data_tensor = torch.tensor(market_data, dtype=torch.float32)  # 转换为 Tensor\n",
    "\n",
    "data = Data(x=x_tensor, edge_index=edge_index_tensor, y=y_tensor, ext_features=market_data_tensor)\n",
    "\n",
    "# 6. 创建数据加载器\n",
    "dataset = [data] * 100  # 生成 100 个样本\n",
    "train_loader = DataLoader(dataset[:80], batch_size=16, shuffle=True)  # 训练集\n",
    "test_loader = DataLoader(dataset[80:], batch_size=16)  # 测试集\n",
    "\n",
    "# 输出样本数据\n",
    "print(\"Sample Node Features (x):\", x_tensor[0])\n",
    "print(\"Sample Edge Index:\", edge_index_tensor)\n",
    "print(\"Sample External Features:\", market_data_tensor[0])\n",
    "print(\"Sample Target (y):\", y_tensor[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e65a6306-ed1f-4321-a852-d38fc91aef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalConvLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3):\n",
    "        super(TemporalConvLayer, self).__init__()\n",
    "        # 使用padding确保输出的时间步长与输入一致\n",
    "        self.conv1d = nn.Conv1d(in_channels, out_channels, kernel_size, padding=(kernel_size // 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x 的形状: [batch, features, timesteps]\n",
    "        x = self.conv1d(x)\n",
    "        return torch.relu(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e13bafe0-320a-4bad-b38d-f486c5ba0266",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialAttentionLayer(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(SpatialAttentionLayer, self).__init__()\n",
    "        self.attention_weights = nn.Linear(in_channels, 1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x 的形状: [num_nodes, in_channels]\n",
    "        attention_scores = torch.sigmoid(self.attention_weights(x))\n",
    "        x = x * attention_scores\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba7a79c6-ebd3-4458-a4b1-05d0744b11ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class STGCNWithAttention(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, ext_feature_dim):\n",
    "        super(STGCNWithAttention, self).__init__()\n",
    "        self.temporal1 = TemporalConvLayer(in_channels + ext_feature_dim, hidden_channels)\n",
    "        self.spatial = SpatialAttentionLayer(hidden_channels)\n",
    "        self.temporal2 = TemporalConvLayer(hidden_channels, out_channels)\n",
    "        self.fc = nn.Linear(out_channels, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, ext_features):\n",
    "        batch_size, num_nodes, feat_dim, timesteps = x.shape\n",
    "        ext_features = ext_features.unsqueeze(1).repeat(1, num_nodes, 1, timesteps)\n",
    "        x = torch.cat([x, ext_features], dim=2)\n",
    "\n",
    "        # 第一层时间卷积\n",
    "        x = self.temporal1(x)\n",
    "        # 进行空间卷积\n",
    "        x = x.view(-1, x.size(2), x.size(3))\n",
    "        x = self.spatial(x, edge_index)\n",
    "        x = x.view(batch_size, num_nodes, -1, x.size(-1))\n",
    "\n",
    "        # 第二层时间卷积\n",
    "        x = self.temporal2(x)\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97915885-b345-4497-bee0-d3d6aea87c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 100\n",
    "timesteps = 10\n",
    "feature_dim = 5\n",
    "ext_feature_dim = 3\n",
    "\n",
    "x = torch.rand((num_nodes, feature_dim, timesteps))\n",
    "edge_index = torch.tensor([[0, 1, 2], [1, 2, 3]], dtype=torch.long)\n",
    "ext_features = torch.rand((ext_feature_dim, timesteps))\n",
    "y = torch.rand((num_nodes,))\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index, y=y, ext_features=ext_features)\n",
    "\n",
    "dataset = [data] * 100\n",
    "train_loader = DataLoader(dataset[:80], batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(dataset[80:], batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd60adf3-2de9-47ca-97d1-397b85669f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, optimizer, criterion, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for data in data_loader:\n",
    "            optimizer.zero_grad()\n",
    "            x, edge_index, y = data.x, data.edge_index, data.y\n",
    "            output = model(x, edge_index, data.ext_features)\n",
    "            loss = criterion(output, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(data_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba81313f-eb26-44b1-aa6f-80feb26285b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m      3\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[1;32m----> 5\u001b[0m train(model, train_loader, optimizer, criterion, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, data_loader, optimizer, criterion, epochs)\u001b[0m\n\u001b[0;32m      6\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m      7\u001b[0m x, edge_index, y \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index, data\u001b[38;5;241m.\u001b[39my\n\u001b[1;32m----> 8\u001b[0m output \u001b[38;5;241m=\u001b[39m model(x, edge_index, data\u001b[38;5;241m.\u001b[39mext_features)\n\u001b[0;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, y)\n\u001b[0;32m     10\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[5], line 10\u001b[0m, in \u001b[0;36mSTGCNWithAttention.forward\u001b[1;34m(self, x, edge_index, ext_features)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index, ext_features):\n\u001b[1;32m---> 10\u001b[0m     batch_size, num_nodes, feat_dim, timesteps \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     11\u001b[0m     ext_features \u001b[38;5;241m=\u001b[39m ext_features\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m, num_nodes, \u001b[38;5;241m1\u001b[39m, timesteps)\n\u001b[0;32m     12\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([x, ext_features], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 3)"
     ]
    }
   ],
   "source": [
    "model = STGCNWithAttention(in_channels=5, hidden_channels=32, out_channels=16, ext_feature_dim=3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "train(model, train_loader, optimizer, criterion, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348b10db-162c-4d3a-855f-defc7861f11f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44056c15-b2e2-4b22-8280-bc485255ecb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
